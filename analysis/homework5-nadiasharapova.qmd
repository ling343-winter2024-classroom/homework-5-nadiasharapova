---
title: "Homework 5: Maze Analysis"
author: "Nadia Sharapova"
format: 
  html:
    code-fold: true
    code-tools: true
editor_options: 
  chunk_output_type: console
---

## Introduction and Overview of Study

This study examined how our brains interpret and predict what words are coming next when we read or listen to someone speaking. The maze task was used to study how we anticipate words in a sentence by measuring a/an contrast in incremental processes. The study looked to support the theory that predictive processes play a large role in language comprehension.

In the maze task, individuals were presented with sentences like "The reporter had dinner yesterday with the baseball player who Kevin admired" along with a sequence of choices between two alternatives for continuing the sentence. The two alternatives were either the correct continuation of the sentence or a Distractor that is either anomalous given the sentence context or pseudo words. This study used an A-maze task to manipulate noun predictability and analyze how prediction occurs in the field of linguistics.

## Setup

```{r message= FALSE, warning=FALSE}
library(lme4)
library(tidyverse)
library(stringr)
library(ggplot2)
library(here)
library(kableExtra)
library(gt)
library(plotly)
library(here)
```

## Importing Data and Changing Directory for Analysis

```{r}
#directory <- "C:\\Users\\cpgl0052\\Dropbox\\Research\\delong maze\\"
here :: i_am ("analysis/homework5-nadiasharapova.qmd")

d <- read.csv(here("data/delong maze 40Ss.csv"),
  header = 1, sep = ",", comment.char = "#", strip.white = T,
  col.names = c("Index", "Time", "Counter", "Hash", "Owner", 
                "Controller", "Item", "Element", "Type", "Group", 
                "FieldName", "Value", "WordNum", "Word", "Alt", 
                "WordOn", "CorrWord", "RT", "Sent", "TotalTime", 
                "Question", "Resp", "Acc", "RespRT"))

df_all <- d

```

## Codebook/Data Dictionary

| Variable   | Meaning                                         |
|------------|-------------------------------------------------|
| Index      | Results Index                                   |
| Time       | Time                                            |
| Counter    | Counter                                         |
| Hash       | Hash                                            |
| Owner      | Logged in as experiment owner? (if known)       |
| Controller | Controller Name                                 |
| Item       | Item Number                                     |
| Element    | Element Number                                  |
| Type       | Type                                            |
| Group      | Group                                           |
| FieldName  | Field name                                      |
| Value      | Field Value                                     |
| WordNum    | Word Number                                     |
| Word       | Word                                            |
| Alt        | Alternative                                     |
| WordOn     | Word on(0=left, 1=right)                        |
| CorrWord   | Correct                                         |
| RT         | Reading time to first answer                    |
| Sent       | Sentence                                        |
| TotalTime  | Total Time to Correct Answer                    |
| Question   | Question (NULL if none).                        |
| Resp       | Answer                                          |
| Acc        | Whether or not answer was correct (NULL if N/A) |
| RespRT     | Time taken to answer                            |

: [**Maze Task Data Dictionary**]{.underline}

## How many participants do you have data for in total?

For this step, I wanted to calculate the number of participants that I had data for. In the study, there were initially 40 participants, however one participant's results didn't transfer so there were only 39 for initial analysis. I also screened out the tenth row to remove the first row from the original data, which just had the label for my column "hash." This meant that there were 38 participants that I had data for that I could analyze.

```{r}
 num_participants <- d %>% 
   count(Hash)

num_participants <- num_participants[-10,]

count(num_participants)

```

## How many rows of data remained after removing the trials as described in the "data analysis" section?

For this step, item 29 was removed as there was a coding error. This left 67526 rows after removing the trials described in the data analysis section.

```{r}
df_all <- read.csv(here("data/delong maze 40Ss.csv"),
  header = 1, sep = ",", comment.char = "#", strip.white = T,
  col.names = c("Index", "Time", "Counter", "Hash", "Owner", 
                "Controller", "Item", "Element", "Type", "Group", 
                "FieldName", "Value", "WordNum", "Word", "Alt", 
                "WordOn", "CorrWord", "RT", "Sent", "TotalTime", 
                "Question", "Resp", "Acc", "RespRT"))

df_rt <- df_all |> 
  filter(Controller == "Maze" & !str_detect(Type, "prac")) |> 
  select(1:10, 13:20) |> 
  separate(col = Type, 
           into = c("exp", "item", "expect", "position", "pos", 
                    "cloze", "art.cloze", "n.cloze"), 
           sep = "\\.", convert = TRUE, fill = "right") |> 
  mutate(WordNum = as.numeric(WordNum),
         Acc = as.numeric(as.character(recode(CorrWord, yes = "1", no = "0"))),
         n.cloze.scale =  scale(n.cloze), 
         art.cloze.scale = scale(art.cloze)) |> 
  mutate(across(where(is.character), as.factor)) |> 
  filter(item != 29) |> 
  filter(Hash != "9dAvrH0+R6a0U5adPzZSyA")

count(df_rt)

```

## Table showing the mean, min, max, and standard deviation of participant ages.
```{r}
demo <- d[d$Controller == "Form",1:12]
names(demo) <- c("Subject","MD5","TrialType","Number","Element","Experiment","Item","Field","Response","X","field","resp")
demo <- as.data.frame(lapply(demo, function (x) if (is.factor(x) | is.character(x)) factor(x) else x))


age_summary <- demo %>% 
  filter(field == "age") %>% 
  summarize(m.age = mean(as.numeric(as.character(resp))), 
                                              min.age = min(as.numeric(as.character(resp))), 
                                              max.age = max(as.numeric(as.character(resp))),
                                              sd.age = sd(as.numeric(as.character(resp))))

age_summary_df <- as.data.frame(age_summary)

age_summary_table <- knitr :: kable(age_summary_df, format= "markdown")

print(age_summary_table)
```



## Recreate Figure 1
```{r}
rt <- d[d$Controller == "Maze" & substr(d$Type,1,4) != "prac", c(1:10,13:20)]
rt <- separate(data = rt, col = Type, into = c("exp", "item", "expect", "position", "pos", "cloze", "art.cloze", "n.cloze"), sep = "\\.", convert = TRUE, fill = "right")
rt <- as.data.frame(lapply(rt, function (x) if (is.factor(x) | is.character(x)) factor(x) else x))
rt$WordNum <- as.numeric(as.character(rt$WordNum))
rt$RT <- as.numeric(as.character(rt$RT))
rt$TotalTime <- as.numeric(as.character(rt$TotalTime))
rt$Acc <- as.numeric(as.character(recode(rt$CorrWord, yes = "1", no = "0")))
rt$n.cloze.scale <- scale(rt$n.cloze)
rt$art.cloze.scale <- scale(rt$art.cloze)


rt.s <- rt[rt$Hash != '9dAvrH0+R6a0U5adPzZSyA',]

rt.s$rgn.fix <- rt.s$WordNum - rt.s$pos + 1
rt.s$word.num.z <- scale(rt.s$WordNum)
rt.s$word.len <- nchar(as.character(rt.s$Word))
rt.s$Altword.len <- nchar(as.character(rt.s$Alt))
contrasts(rt.s$expect) <- c(-.5,.5)

rt.s$item.expect <- paste(rt.s$item, rt.s$expect, sep=".")
delong.items <- rt.s %>% filter(rgn.fix == 0) %>% distinct(item.expect, .keep_all = TRUE)

#Response accuracy

rt.s.filt <- rt.s[rt.s$Hash != "gyxidIf0fqXBM7nxg2K7SQ" & rt.s$Hash != "f8dC3CkleTBP9lUufzUOyQ",]

rt.s.rgn <- rt.s.filt %>% filter(rgn.fix > -4 & rgn.fix < 5) %>% filter(Acc == 1) %>% as.data.frame()

rgn.rt.raw <- rt.s.filt %>% filter(rgn.fix > -4 & rgn.fix < 5) %>% filter(Acc == 1) %>% group_by(rgn.fix, expect) %>% summarize(n=n(), subj=length(unique(Hash)), rt=mean(RT), sd=sd(RT), stderr=sd/sqrt(subj)) %>% as.data.frame()
rgn.rt.raw$rgn <- as.factor(recode(rgn.rt.raw$rgn.fix, "-3"="CW-3", "-2"="CW-2", "-1"="CW-1", "0"="art", "1"="n","2"="CW+1", "3"="CW+2", "4"="CW+3"))
rgn.rt.raw$rgn <- ordered(rgn.rt.raw$rgn, levels = c("CW-3", "CW-2", "CW-1", "art", "n", "CW+1", "CW+2", "CW+3"))
ggplot(rgn.rt.raw, aes(x=rgn, y=rt, group=expect, shape=expect)) +
  geom_line(stat = "identity", position=position_dodge(width=.3)) +
  geom_point(stat = "identity", position=position_dodge(width=.3), size=3) +
  geom_errorbar(aes(ymin = rt-stderr, ymax = rt+stderr), width=.15, position=position_dodge(width=.3)) +
  scale_shape_manual(name="", labels=c("Expected", "Unexpected"), values = c(21,19)) + 
  xlab("Word") + ylab("Reading Time (msec)") + 
  theme_bw()
```

7. Include a table showing the same results as in Figure 1 - you can skip the standard error numbers if that is too challenging. 
```{r}
summary_rgn <- rgn.rt.raw %>% 
  group_by(rgn, expect) %>% 
  summarize(
    Mean_RT= mean(rt),
    Min_RT= min(rt),
    Max_RT=max(rt)
  )

print(summary_rgn)
```

